\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage{natbib}
\usepackage{url}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\graphicspath{{images/}}
\usepackage{parskip}
\usepackage{fancyhdr}
\usepackage{vmargin}
\usepackage{ctex}
\usepackage[noend]{algpseudocode}
\usepackage{algorithmicx,algorithm}
\usepackage{pythonhighlight}
\setlength{\parindent}{2em}
\setmarginsrb{3 cm}{2.5 cm}{3 cm}{2.5 cm}{1 cm}{1.5 cm}{1 cm}{1.5 cm}
\title{ 前沿数学专题讨论 PR05}								% Title
\author{22-23秋冬}								% Author
\date{30 Nov 2022}	% Date

\makeatletter
\let\thetitle\@title
\let\theauthor\@author
\let\thedate\@date
\makeatother

\pagestyle{fancy}
\fancyhf{}
\rhead{\theauthor}
\lhead{\thetitle}
\cfoot{\thepage}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{titlepage}
	\centering
    \vspace*{0.5 cm}
    \includegraphics[scale = 0.5]{logo.jpeg}\\[1.0 cm]	% University Logo
	% University Name
	\textsc{\Large \textbf{浙江大学数学科学学院} }\\[0.5 cm]				% Course Code
	\rule{\linewidth}{0.2 mm} \\[0.4 cm]
	{ \huge \bfseries \thetitle}\\
	\rule{\linewidth}{0.2 mm} \\[1.5 cm]
	{  \bfseries \thedate}\\
	\vskip 0.6 in
	\begin{minipage}{0.4\textwidth}
		\begin{flushleft} \large
			\emph{Submitted To:}\\
			张南松老师\\
                22-23秋冬学期\\
			\end{flushleft}
			\end{minipage}~
			\begin{minipage}{0.4\textwidth}
            
			\begin{flushright} \large
			\emph{Submitted By :} \\
			吴凡\\
            农业工程+统计学\\
		\end{flushright}
        
	\end{minipage}\\[2 cm]		    
	
\end{titlepage}

\tableofcontents
\pagebreak




\section{Evolution Strategy}
Evolution strategies (ES) belong to the big family of evolutionary algorithms.
The optimization targets of ES are vectors of real numbers,$x \in R^n $.

Evolutionary algorithms refer to a division of population-based optimization algorithms inspired by natural selection. Natural selection believes that individuals with traits beneficial to their survival can live through generations and pass down the good characteristics to the next generation. Evolution happens by the selection process gradually and the population grows better adapted to the environment.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=10cm]{zr.png}
\end{figure}

Evolutionary algorithms can be summarized in the following format as a general optimization solution:

Let's say we want to optimize a function f(x) and we are not able to 
compute gradients directly. But we still can evaluate f(x) given any x  
and the result is deterministic. Our belief in the probability 
distribution over x as a good solution to f(x) optimization is $p_\theta (x)$, 
parameterized by $\theta$ . 
The goal is to find an optimal configuration of $\theta$ .


Starting with an initial value of $\theta$ ,
 we can continuously update $\theta$ by looping three steps as follows:
\begin{enumerate}
	\item Generate a population of samples $D={(x_i,f(x_i))}$ where $x_i\sim p_\theta(x)$
	\item Evaluate the "fitness" of samples in D.
	\item Select the best subset of individuals and use them to update $\theta$,generally bases on fitness or rank. 
\end{enumerate}

The most basic and canonical version of evolution strategies:Simple Gaussian Evolution Strategies.
It models $p_\theta (x)$ as 
a n-dimensional isotropic Gaussian distribution, 
in which $\theta$ only tracks the mean $\mu$  and standard deviation $\sigma$.
\begin{align}
	\theta=(\mu,\sigma),p_\theta (x)\sim N(\mu,\sigma^2I)=\mu+\sigma N(0,I)
\end{align}

The process of  Simple-Gaussian-ES, given $x\in R^n$:

\begin{enumerate}
	\item Initialize $\theta=\theta^{(0)}$ and the generation counter t=0
	\item Generate the offspring population of size $\Lambda $
	by sampling from the Gaussian distribution:
	\begin{align}
		D^{(t+1)}={x_i^{(t+1)}|x_i^{(t+1)}=\mu^{(t)}+\sigma^{(t)}y_i^{(t+1)} where y_i^{(t+1)}\sim N(x|0,I);i=1,\cdots,\Lambda }
	\end{align}
	\item Select a top subset of $\lambda$  
	samples with optimal $f(x_i)$ and this subset is 
	called \textbf{elite} set. 
	Let's label them as
	\begin{align}
		D^{(t+1)}_{elite}=x_i^{(t+1)}|x_i^{(t+1)}\in D^{(t+1)},i=1,\cdots,\lambda,\lambda \leq \Lambda 
	\end{align}
	\item Then we estimate the new mean and std for the next generation using the elite set:
	\begin{gather}
		\mu^{(t+1)}=avg(D^{(t+1)}_{elite})=\frac{1}{\lambda}\sum_{i=1}^\lambda x_i^{(t+1)}\\
		\sigma^{(t+1)^2}=var(D^{(t+1)}_{elite})=\frac{1}{\lambda}\sum_{i=1}^\lambda (x_i^{(t+1)}-\mu^{(t)})^2
	\end{gather} 
	\item Repeat steps 2-4 until the result is good enough.
\end{enumerate}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=8cm]{1.png}
\end{figure}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=8cm]{2.png}
\end{figure}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=8cm]{3.png}
\end{figure}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=8cm]{4.png}
\end{figure}

\section{CMA Evolution Strategy}
The standard deviation $\sigma$ accounts for the 
level of exploration: the larger $\sigma$ the bigger 
search space we can sample our offspring population. 
In vanilla ES, $\sigma^{(t+1)}$ is highly correlated 
with $\sigma^{t}$, so the algorithm is not able to rapidly adjust the exploration space when needed (i.e. when the confidence level changes).

CMA-ES, short for “Covariance Matrix Adaptation 
Evolution Strategy”, fixes the problem by tracking 
pairwise dependencies between the samples in the 
distribution with a covariance matrix C. 
The new distribution parameter becomes:
\begin{align}
	\theta=(\mu,\sigma,C),p_\theta(x)\sim N(\mu,\sigma^2C)\sim\mu+\sigma N(0,C)
\end{align}
where $\sigma$ controls for the overall scale of the distribution,often knoen as step size.

Compared with ES mentioned above:
\begin{align}
	\theta=(\mu,\sigma),p_\theta (x)\sim N(\mu,\sigma^2I)=\mu+\sigma N(0,I)
\end{align}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=14cm]{symbol.png}
\end{figure}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=15cm]{wdm.png}
\end{figure}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=8cm]{cma.png}
\end{figure}

\subsection{Updating the Mean}
\begin{align}
	\mu^{(t+1)}=\mu^{(t)}+\alpha_\mu \frac{1}{\lambda}\sum_{i=1}^\lambda(x_i^{(t+1)}-\mu^{(t)})	
\end{align}
CMA-ES has a learning rate $\alpha_\mu\leq 1$ to control 
how fast the mean  should be updated. 

\subsection{Controlling the Step Size}
The sampling process can be decoupled from the mean and standard deviation:
\begin{align}
	x_i^{(t+1)}=\mu^{(t)}+\sigma^{(t)}y_i^{(t+1)}, where y_i^{(t+1)}=\frac{x_i^{(t+1)}-\mu^{(t)}}{\sigma^{(t)}}\sim N(0,C)
\end{align}

The parameter $\sigma$  controls the overall scale of the distribution. 
It is separated from the covariance matrix so that we can change steps 
faster than the full covariance. 
A larger step size leads to faster parameter update. 
In order to evaluate whether the current step size is proper, CMA-ES 
constructs an evolution path $p_\sigma$ 
by summing up a consecutive sequence of moving steps.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=14cm]{path.png}
\end{figure}

By comparing this path length with its expected length 
under random selection (meaning single steps are uncorrelated), 
we are able to adjust $\sigma$ accordingly.

\begin{gather}
	\frac{1}{\lambda}\sum_{i=1}^{\lambda}y_i^{(t+1)}=\frac{\mu^{(t+1)}-\mu^{(t)}}{\sigma^{(t)}}\\
	\frac{1}{\lambda}\sum_{i=1}^{\lambda}y_i^{(t+1)}\sim\frac{1}{\lambda}N(0,\lambda C^{(t)})\sim \frac{1}{\sqrt{\lambda}}C^{(t)^{\frac{1}{2}}}N(0,I)\\
	\Longrightarrow \sqrt{\lambda}C^{(t)^{-\frac{1}{2}}}\frac{\mu^{(t+1)}-\mu^{(t)}}{\sigma^{(t)}}\sim N(0,I)
\end{gather}

In order to assign higher weights to recent generations, 
we use polyak averaging to update the evolution path with learning rate $\alpha_\sigma$.
Meanwhile, the weights are balanced so that $p_\sigma$ is conjugate,$\sim N(0,I)$ 
both before and after one update.

\begin{gather}
	p_\sigma^{(t+1)}=(1-\alpha_\sigma)p_\alpha^{(t)}+\sqrt{c_\sigma(2-\alpha_\sigma)\lambda}C^{(t)^{-\frac{1}{2}}}\frac{\mu^{(t+1)}-\mu^{(t)}}{\sigma^{(t)}}
\end{gather}

The expected length of $p_\sigma$ under random selection is $E|N(0,I)|$, 
that is the expectation of the L2-norm of a N(0,I) random variable.

We adjust the step size according to the ratio of $\frac{||p_\sigma^{(t+1)}||}{E||N(0,I)||}$

\begin{gather}
	ln \sigma^{(t+1)}=ln \sigma^{(t)}+\frac{\alpha_\sigma}{d_\sigma}(\frac{||p_\sigma^{(t+1)}||}{E||N(0,I)||}-1)\\
     \sigma^{(t+1)}= \sigma^{(t)} exp(\frac{\alpha_\sigma}{d_\sigma}(\frac{||p_\sigma^{(t+1)}||}{E||N(0,I)||}-1))
\end{gather}

where $d_\sigma \approx  1$ is a damping parameter, scaling how fast
$ln \sigma$  should be changed.

\subsection{Adapting the Covariance Matrix}

For the covariance matrix, it can be estimated from scratch using
$y_i$ of elite samples(recall that $y_i\sim N(0,C)$)
\begin{gather}
	C_\lambda^{(t+1)}=\frac{1}{\lambda}\sum_{i=1}^\lambda y_i^{(t+1)}y_i^{(t+1)^T}
\end{gather}

The above estimation is only reliable when the selected population is large enough. However, we do want to run fast iteration with a small population of samples in each generation. 
That's why CMA-ES invented a more reliable but also more complicated way 
to update C. 

It involves two independent routes:
\begin{itemize}
	\item \textbf{Rank-min($\lambda$,n) update}:uses the history of ${C_\lambda}$, each estimated from scratch in one generation.
	\item \textbf{Rank-one update}:estimates the moving 
	steps $y_i$ and the sign information from the history.
\end{itemize}

\begin{enumerate}
	\item For the first part:\\
	The first route considers the estimation of C from the entire history
	 of ${C_\lambda}$. 
	For example, if we have experienced a large number of generations,
	$C^{(t+1)}\approx avg(C_\lambda^{(i)};i=1,\cdots,t)$ 
 would be a good estimator. Similar to $p_\sigma$, we also use polyak averaging with a learning rate to incorporate the history:
 \begin{gather}
	C^{(t+1)}=(1-\alpha_{c\lambda})C^{(t)}+\alpha_{c\lambda}C^{(t+1)}\\
    C^{(t+1)}=(1-\alpha_{c\lambda})C^{(t)}+\alpha_{c\lambda}\frac{1}{\lambda}\sum_{i=1}^\lambda y_i^{(t+1)}y_i^{(t+1)^T}
 \end{gather}

 A common choice for the learning rate is $\alpha_{c\lambda}\approx min(1,\lambda/n^2)$.
	\item For the second part:\\
	Similar to how we adjust the step size $\sigma$,
	 an evolution path $p_c$ is used to track the sign information and 
	 it is constructed in a way that $p_c$ is conjugate, $\sim N(0,C)$
	 both before and after a new generation.	

	 We may consider $p_c$ as another way to compute $avg_i(y_i)$ 
	 (notice that both $\sim N(0,C)$ ) while the entire history 
	 is used and the sign information is maintained.

	 In the last section,we know that:
	 \begin{align} 
		\sqrt{\lambda}\frac{\mu^{(t+1)}-\mu^{(t)}}{\sigma^{(t)}}\sim N(0,C)
	 \end{align}
	 We define:
	 \begin{gather}
		p_c^{(t+1)}=(1-\alpha_{cp})p_c^{(t)}+\sqrt{1-(1-\alpha_{cp})^2}\sqrt{\lambda}\frac{\mu^{(t+1)}-\mu^{(t)}}{\sigma^{(t)}}\\
		p_c^{(t+1)}=(1-\alpha_{cp})p_c^{(t)}+\sqrt{\alpha_{cp}(2-\alpha_{cp})\lambda}\frac{\mu^{(t+1)}-\mu^{(t)}}{\sigma^{(t)}}
	 \end{gather}
	 Then the covariance matrix is updated according to $p_c$:
	 \begin{gather}
		C^{(t+1)}=(1-\alpha_{c1})C^{(t)}+\alpha_{c1}p_c^{(t+1)}p_c^{(t+1)^T}
	 \end{gather}
\end{enumerate}

Eventually we combine two approaches together:
\begin{figure}[htbp]
	\centering
	\includegraphics[width=15cm]{equa.png}
\end{figure}


\begin{figure}[htbp]
	\centering
	\includegraphics[width=12cm]{gen.png}
\end{figure}
Black dots are samples in one generation. The samples are more spread out initially but when the model has higher confidence in finding a good solution in the late stage, the samples become very concentrated over the global optimum. 

\newpage
\section{Appendix: Code}
\subsection{ES}
\begin{python}
import numpy as np
import matplotlib.pyplot as plt

DNA_SIZE = 1             # DNA (real number)
DNA_BOUND = [0, 20]       # solution upper and lower bounds
N_GENERATIONS = 200
POP_SIZE = 100           # population size
N_KID = 50               # n kids per generation


def F(x): return np.sin(10*x)*x + np.cos(2*x)*x     # to find the maximum of this function


# find non-zero fitness for selection
def get_fitness(pred): return pred.flatten()


def make_kid(pop, n_kid):
    # generate empty kid holder
    kids = {'DNA': np.empty((n_kid, DNA_SIZE))}
    kids['mut_strength'] = np.empty_like(kids['DNA'])
    for kv, ks in zip(kids['DNA'], kids['mut_strength']):
        # crossover (roughly half p1 and half p2)
        p1, p2 = np.random.choice(np.arange(POP_SIZE), size=2, replace=False)
        cp = np.random.randint(0, 2, DNA_SIZE, dtype=np.bool)  # crossover points
        kv[cp] = pop['DNA'][p1, cp]
        kv[~cp] = pop['DNA'][p2, ~cp]
        ks[cp] = pop['mut_strength'][p1, cp]
        ks[~cp] = pop['mut_strength'][p2, ~cp]

        # mutate (change DNA based on normal distribution)
        ks[:] = np.maximum(ks + (np.random.rand(*ks.shape)-0.5), 0.)    # must > 0
        kv += ks * np.random.randn(*kv.shape)
        kv[:] = np.clip(kv, *DNA_BOUND)    # clip the mutated value
    return kids


def kill_bad(pop, kids):
    # put pop and kids together
    for key in ['DNA', 'mut_strength']:
        pop[key] = np.vstack((pop[key], kids[key]))

    fitness = get_fitness(F(pop['DNA']))            # calculate global fitness
    idx = np.arange(pop['DNA'].shape[0])
    good_idx = idx[fitness.argsort()][-POP_SIZE:]   # selected by fitness ranking (not value)
    for key in ['DNA', 'mut_strength']:
        pop[key] = pop[key][good_idx]
    return pop


pop = dict(DNA=5 * np.random.rand(1, DNA_SIZE).repeat(POP_SIZE, axis=0),   # initialize the pop DNA values
           mut_strength=np.random.rand(POP_SIZE, DNA_SIZE))                # initialize the pop mutation strength values

plt.ion()       # something about plotting
x = np.linspace(*DNA_BOUND, 200)
plt.plot(x, F(x))

for _ in range(N_GENERATIONS):
    # something about plotting
    if 'sca' in globals(): sca.remove()
    sca = plt.scatter(pop['DNA'], F(pop['DNA']), s=200, lw=0, c='red', alpha=0.5); plt.pause(0.05)

    # ES part
    kids = make_kid(pop, N_KID)
    pop = kill_bad(pop, kids)   # keep some good parent for elitism

plt.ioff(); plt.show()

\end{python}

\subsection{CMA-ES}
\begin{python}
	import numpy as np
	import numpy.linalg as la
	
	
	from matplotlib import cm
	import matplotlib.pyplot as plt
	from mpl_toolkits.mplot3d import Axes3D
	
	import cma
	
	np.random.seed(0)
	
	"""
	The Algorithm
	
	Paramters
	Population size  : N
	Covariance Matrix: C
	mean of best k   : mu
	
	1. Sample N from multivariate normal distribution
	2. Calculate fitness and 
	
	"""
	
	def rastrigin(X, A=10):
		return A + np.sum((X**2 - A * np.cos(2 * np.pi * X)), -1)
	
	def rosenbrock(X, a=1, b=100):
		x,y = X[...,0], X[...,1]
		return (a-x)**2 + b*(y-x**2)**2
	
	#(1-x)^2+100(y-x^2)^2
		
	
	def _plot_points(X, low=-10, high=10, size=1024):
		""" Plots the points on same scale as image """
		tmp = (X - low)/(high-low) * size
		plt.scatter(tmp[:,0], tmp[:,1], color='black', alpha=.5)
	
	if __name__ == '__main__':
	
		low, high, size = -6, 6, 2048
		spacing = np.linspace(low, high, size)    
	
		grid = np.stack(np.meshgrid(spacing, spacing), -1)
		function = lambda X: rastrigin(X + [3,2])   # Move the min away from (0,0)
		#function = rosenbrock
		Z = function(grid)
		
	
		 
		n = 200     # Population size
		d = 2       # Dimensions
		k = 50      # Size of elite population
	
		X = np.random.normal(0,1.24, (d, n))
	
		for i in range(24):
			# Minimize this function
			fitness = function(X.T)
			arg_topk = np.argsort(fitness)[:k]
			topk = X[:,arg_topk]
	
			#print(f'Iter {i}, score {fitness[arg_topk[0]]}, X = {X[:,arg_topk[0]]}')
			# Covariance of topk but using mean of entire population
			centered = topk - X.mean(1, keepdims=True)
			C = (centered @ centered.T)/(k-1)
			# Eigenvalue decomposition
			w, E = la.eigh(C)
			# Generate new population
			# Sample from multivariate gaussian with mean of topk
			N = np.random.normal(size=(d,n))
			X = topk.mean(1,keepdims=True) + (E @ np.diag(np.sqrt(w)) @ N)
			if i % 1 == 0:
				print(f'iter {i}, z= {fitness[arg_topk[0]]:.2f}, x= {X[:, arg_topk[0]].round(2)}')
				plt.clf()
				plt.imshow(Z, cmap='Oranges')
				_plot_points(X.T, low, high, size)
				plt.pause(.2)
				plt.draw()
				plt.savefig(f'plots/fig-{i}.jpg')
\end{python}

\bibliographystyle{plain}
\bibliography{biblist}

\end{document}

